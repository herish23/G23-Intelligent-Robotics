import numpy as np
import time
import csv
import math

# Import all the utilities from your new package
try:
    from localization_utils import (
        load_config,
        print_config_summary,
        get_output_paths,
        MapInfo,
        load_map,
        load_sensor_data,
        compute_likelihood_field,
        compute_scan_likelihood_field,
        grid_to_world,
        world_to_grid
    )
except ImportError:
    print("Error: Could not import the 'localization_utils' package.")
    print("Please ensure the 'localization_utils' directory is in the same folder as this script.")
    exit(1)


def prediction_step(belief_grid, motion, map_info, diffusion_factor):
    """
    Updates the belief grid based on a motion model P(x_t | u_t, x_t-1).
    'motion' is (dx_m, dy_m).
    """
    dx_m, dy_m = motion
    
    # Convert motion from meters to grid cells
    dx_cells = int(round(dx_m / map_info.resolution))
    dy_cells = int(round(dy_m / map_info.resolution))
    
    # This is a simple "shift" model.
    predicted_belief = np.roll(belief_grid, (dy_cells, dx_cells), axis=(0, 1))
    
    # Zero out probabilities that "leaked" from the other side
    if dy_cells > 0:
        predicted_belief[:dy_cells, :] = 0
    elif dy_cells < 0:
        predicted_belief[dy_cells:, :] = 0
    if dx_cells > 0:
        predicted_belief[:, :dx_cells] = 0
    elif dx_cells < 0:
        predicted_belief[:, dx_cells:] = 0

    # Add a simple diffusion model for motion noise (prevents particle deprivation)
    uniform_prob = 1.0 / belief_grid.size
    final_belief = predicted_belief * (1.0 - diffusion_factor) + \
                   (uniform_prob * diffusion_factor)
    
    # Mask out any probabilities in occupied cells
    final_belief[map_info.occupancy_grid > 0.5] = 0.0

    # Normalize the belief
    total_prob = np.sum(final_belief)
    if total_prob > 0:
        return final_belief / total_prob
    else:
        # Failsafe: re-initialize if all probability is lost
        return np.ones_like(belief_grid) / belief_grid.size

def correction_step(belief_grid, sensor_data, map_info, likelihood_field, config):
    """
    Updates the belief grid based on the sensor model P(z_t | x_t)
    using the pre-computed likelihood field.
    """
    
    lidar_config = config['sensors']['lidar']
    lidar_ranges = sensor_data['ranges']
    
    # Create an array of lidar angles
    angles = np.linspace(
        -math.radians(lidar_config['fov_deg']) / 2.0,
        math.radians(lidar_config['fov_deg']) / 2.0,
        lidar_config['num_rays']
    )
    
    # Apply sparsity
    sparse_indices = np.arange(0, len(lidar_ranges), lidar_config['sparsity'])
    sparse_ranges = lidar_ranges[sparse_indices]
    sparse_angles = angles[sparse_indices]

    # ** This is the 2D "cheat" **
    # We use the ground truth theta for the sensor model.
    # This simplifies the problem from 3D (x,y,theta) to 2D (x,y).
    gt_theta_rad = sensor_data['pose'][2]

    # Create a likelihood grid (log-probabilities)
    log_likelihood_grid = np.zeros_like(belief_grid)
    
    print("  Running correction step (using likelihood field)...")
    
    for y in range(map_info.height):
        for x in range(map_info.width):
            if map_info.occupancy_grid[y, x] > 0.5:
                log_likelihood_grid[y, x] = -np.inf # Impossible to be in a wall
                continue

            # Get world coordinates for the center of this grid cell
            wx, wy = grid_to_world(x, y, map_info)
            
            # Calculate log-likelihood P(z | x)
            # This is MUCH faster than ray-casting
            log_p = compute_scan_likelihood_field(
                sparse_ranges, sparse_angles, 
                wx, wy, gt_theta_rad,
                map_info, likelihood_field
            )
            log_likelihood_grid[y, x] = log_p

    print("  Correction step done.")

    # Convert from log-probability to probability
    # Subtract max for numerical stability
    likelihood_grid = np.exp(log_likelihood_grid - np.max(log_likelihood_grid))
    
    # Update belief: Bel(x_t) = eta * P(z_t | x_t) * Bel_bar(x_t)
    updated_belief = belief_grid * likelihood_grid
    
    # Normalize the final belief
    total_prob = np.sum(updated_belief)
    if total_prob > 0:
        return updated_belief / total_prob
    else:
        # Failsafe
        print("  Warning: Belief collapsed. Re-initializing.")
        return np.ones_like(belief_grid) / belief_grid.size

def main():
    config_path = 'config.yaml'
    print(f"Loading configuration from {config_path}...")
    config = load_config(config_path)
    print_config_summary(config)
    
    # --- 1. Load Map ---
    print("\nLoading map...")
    try:
        map_info = load_map(
            config['data']['map_pgm_path'], 
            config['data']['map_yaml_path']
        )
        print(f"Map loaded: {map_info.width}x{map_info.height} cells @ {map_info.resolution:.3f} m/cell")
    except FileNotFoundError as e:
        print(f"Error loading map: {e}")
        print("Please ensure 'map_pgm_path' and 'map_yaml_path' in config.yaml are correct.")
        print("You must provide the .pgm file yourself.")
        return

    # --- 2. Pre-compute Likelihood Field ---
    print("Pre-computing likelihood field (this may take a moment)...")
    start_time = time.time()
    likelihood_field = compute_likelihood_field(
        map_info, 
        config['localization']['likelihood_sigma'],
        config['localization']['likelihood_max_dist']
    )
    print(f"Likelihood field computed in {time.time() - start_time:.2f}s")
    
    # --- 3. Initialize Belief ---
    print("Initializing belief grid...")
    # P(x_0) = Uniform distribution
    belief_grid = np.ones((map_info.height, map_info.width))
    # Remove belief from occupied cells
    belief_grid[map_info.occupancy_grid > 0.5] = 0.0
    belief_grid = belief_grid / np.sum(belief_grid)
    
    # --- 4. Load Sensor Data ---
    print("Loading sensor data...")
    # We use the 'load_sensor_data' function we created in data_format.py
    # This assumes the CSV has 'gt_x', 'gt_y', 'gt_theta', and 'range_...' columns
    sensor_log = load_sensor_data(config)
    if not sensor_log:
        print("Failed to load sensor data. Exiting.")
        return
    print(f"Loaded {len(sensor_log)} data points.")

    # --- 5. Run Localization Loop ---
    last_gt_pose = None
    
    for i, sensor_data in enumerate(sensor_log):
        print(f"\n--- Processing Timestamp {sensor_data['timestamp']} (Step {i+1}/{len(sensor_log)}) ---")
        start_step_time = time.time()
        
        current_gt_pose = sensor_data['pose']
        gt_x_m, gt_y_m, gt_theta_rad = current_gt_pose
        gt_grid_x, gt_grid_y = world_to_grid(gt_x_m, gt_y_m, map_info)

        # --- Prediction Step (Motion Model) ---
        if last_gt_pose:
            dx_m = current_gt_pose[0] - last_gt_pose[0]
            dy_m = current_gt_pose[1] - last_gt_pose[1]
            motion = (dx_m, dy_m)
            
            print(f"  Applying motion: dx={dx_m:.2f}m, dy={dy_m:.2f}m")
            belief_grid = prediction_step(
                belief_grid, 
                motion, 
                map_info, 
                config['localization']['motion_diffusion_factor']
            )
        else:
            print("  Skipping prediction step (first frame).")

        # --- Correction Step (Sensor Model) ---
        belief_grid = correction_step(
            belief_grid, 
            sensor_data, 
            map_info, 
            likelihood_field, 
            config
        )

        # --- Find Best Estimate ---
        est_grid_y, est_grid_x = np.unravel_index(
            np.argmax(belief_grid), 
            belief_grid.shape
        )
        est_x_m, est_y_m = grid_to_world(est_grid_x, est_grid_y, map_info)
        max_prob = np.max(belief_grid)
        
        prob_at_gt = 0.0
        if 0 <= gt_grid_x < map_info.width and 0 <= gt_grid_y < map_info.height:
             prob_at_gt = belief_grid[gt_grid_y, gt_grid_x]

        # --- 6. Print and Compare ---
        print("\n  --- Results ---")
        print(f"  Step Time: {time.time() - start_step_time:.2f}s")
        print(f"  Ground Truth (World): ({gt_x_m:.2f}m, {gt_y_m:.2f}m)")
        print(f"  Ground Truth (Grid):  ({gt_grid_x}, {gt_grid_y})")
        print(f"  Estimated Pos (World): ({est_x_m:.2f}m, {est_y_m:.2f}m)")
        print(f"  Estimated Pos (Grid):  ({est_grid_x}, {est_grid_y})")
        print(f"  Highest Belief: {max_prob:.4e}")
        print(f"  Belief at GT:   {prob_at_gt:.4e}")

        # Update last pose for next iteration
        last_gt_pose = current_gt_pose

if __name__ == "__main__":
    main()
