import numpy as np
import time
import csv
import math
import sys
import random 
import os # Added os for path joining

# -----------------------------------------------------------------------------
# CONFIGURATION
# -----------------------------------------------------------------------------
# All settings are in this dictionary. Update the paths to match your system.
# *** IMPORTANT: Update all 3 paths below to be FULL, ABSOLUTE paths ***
# -----------------------------------------------------------------------------
CONFIG = {
    'data': {
        # --- 1. UPDATE THIS PATH ---
        # Must be the FULL, ABSOLUTE path to your sensor data
        'sensor_data_csv_path': r'C:\Users\Rohit\Desktop\Intelligent Robotics\G23-Intelligent-Robotics\data\sensor_data_clean.csv',
        
        # --- 2. UPDATE THESE PATHS ---
        # Must be the FULL, ABSOLUTE paths to your map files
        # --- I'VE UPDATED THESE FILENAMES TO MATCH YOUR MAP FILES ---
        'map_pgm_path': r'C:\Users\Rohit\Desktop\Intelligent Robotics\G23-Intelligent-Robotics\maps\epuck_world_map.pgm',
        'map_yaml_path': r'C:\Users\Rohit\Desktop\Intelligent Robotics\G23-Intelligent-Robotics\maps\epuck_world_map.yaml',
    },
    'sensors': {
        'lidar': {
            'num_rays': 360,     # Total rays in the scan
            'fov_deg': 360,      # Field of view in degrees
            'sparsity': 10,      # Use 1-in-every-X rays (e.g., 10)
        }
    },
    'localization': {
        'likelihood_sigma': 0.5,     # Std. dev. for likelihood field (meters)
        'likelihood_max_dist': 2.0,  # Max distance for likelihood (meters)
        'motion_diffusion_factor': 0.1, # How much to "blur" on prediction
    }
}
# -----------------------------------------------------------------------------


# Add the path to the libraries folder
# Using the absolute path you provided to find 'localization_utils'
sys.path.append(r'C:\Users\Rohit\Desktop\Intelligent Robotics\G23-Intelligent-Robotics\libraries')


# Import all the utilities from your new package
try:
    # --- UPDATED IMPORTS ---
    # We now import directly from the .py files inside the package
    # (as shown in your screenshot). This is more robust.
    from localization_utils.map_loader import MapInfo, load_map
    from localization_utils.data_format import load_sensor_data
    from localization_utils.likelihood_field import (
        compute_likelihood_field, 
    )
    from localization_utils.geometry import grid_to_world, world_to_grid

except ImportError as e:
    print(f"Error: Could not import from the 'localization_utils' package: {e}")
    print(f"Tried to find it in: {sys.path[-1]}")
    print("Please ensure this path is correct and contains the 'localization_utils' folder.")
    exit(1)


def prediction_step(belief_grid, motion, map_info, diffusion_factor):
    """
    Updates the belief grid based on a motion model P(x_t | u_t, x_t-1).
    'motion' is (dx_m, dy_m).
    """
    dx_m, dy_m = motion
    
    # Convert motion from meters to grid cells
    dx_cells = int(round(dx_m / map_info.resolution))
    dy_cells = int(round(dy_m / map_info.resolution))
    
    # This is a simple "shift" model.
    predicted_belief = np.roll(belief_grid, (dy_cells, dx_cells), axis=(0, 1))
    
    # Zero out probabilities that "leaked" from the other side
    if dy_cells > 0:
        predicted_belief[:dy_cells, :] = 0
    elif dy_cells < 0:
        predicted_belief[dy_cells:, :] = 0
    if dx_cells > 0:
        predicted_belief[:, :dx_cells] = 0
    elif dx_cells < 0:
        predicted_belief[:, dx_cells:] = 0

    # Add a simple diffusion model for motion noise (prevents particle deprivation)
    uniform_prob = 1.0 / belief_grid.size
    final_belief = predicted_belief * (1.0 - diffusion_factor) + \
                   (uniform_prob * diffusion_factor)
    
    # Mask out any probabilities in occupied cells
    final_belief[map_info.occupancy_grid > 0.5] = 0.0

    # Normalize the belief
    total_prob = np.sum(final_belief)
    if total_prob > 0:
        return final_belief / total_prob
    else:
        # Failsafe: re-initialize if all probability is lost
        return np.ones_like(belief_grid) / belief_grid.size

def correction_step(belief_grid, sensor_data, map_info, likelihood_field, config):
    """
    Updates the belief grid based on the sensor model P(z_t | x_t)
    using the pre-computed likelihood field.
    """
    
    lidar_config = config['sensors']['lidar']
    lidar_ranges = sensor_data['ranges']
    
    # Create an array of lidar angles
    angles = np.linspace(
        -math.radians(lidar_config['fov_deg']) / 2.0,
        math.radians(lidar_config['fov_deg']) / 2.0,
        lidar_config['num_rays']
    )
    
    # Apply sparsity
    sparse_indices = np.arange(0, len(lidar_ranges), lidar_config['sparsity'])
    sparse_ranges = lidar_ranges[sparse_indices]
    sparse_angles = angles[sparse_indices]

    # ** This is the 2D "cheat" **
    # We use the ground truth theta for the sensor model.
    # This simplifies the problem from 3D (x,y,theta) to 2D (x,y).
    gt_theta_rad = sensor_data['pose'][2]

    # Create a likelihood grid (log-probabilities)
    log_likelihood_grid = np.zeros_like(belief_grid)
    
    print("  Running correction step (using likelihood field)...")
    
    for y in range(map_info.height):
        for x in range(map_info.width):
            if map_info.occupancy_grid[y, x] > 0.5:
                log_likelihood_grid[y, x] = -np.inf # Impossible to be in a wall
                continue

            # Get world coordinates for the center of this grid cell
            wx, wy = grid_to_world(x, y, map_info)
            
            # Calculate log-likelihood P(z | x)
            # This is MUCH faster than ray-casting
            log_p = compute_scan_likelihood_field(
                sparse_ranges, sparse_angles, 
                wx, wy, gt_theta_rad,
                map_info, likelihood_field
            )
            log_likelihood_grid[y, x] = log_p

    print("  Correction step done.")

    # Convert from log-probability to probability
    # Subtract max for numerical stability
    # Find the max finite log-likelihood
    max_log_like = np.max(log_likelihood_grid[np.isfinite(log_likelihood_grid)])
    likelihood_grid = np.exp(log_likelihood_grid - max_log_like)
    
    # Update belief: Bel(x_t) = eta * P(z_t | x_t) * Bel_bar(x_t)
    updated_belief = belief_grid * likelihood_grid
    
    # Normalize the final belief
    total_prob = np.sum(updated_belief)
    if total_prob > 0:
        return updated_belief / total_prob
    else:
        # Failsafe
        print("  Warning: Belief collapsed. Re-initializing.")
        return np.ones_like(belief_grid) / belief_grid.size

def main():
    # Removed config loading
    print(f"Loading configuration from internal CONFIG dictionary...")
    # Use the global CONFIG object
    config = CONFIG 
    
    # --- 1. Load Map ---
    print("\nLoading map...")
    try:
        map_info = load_map(
            config['data']['map_pgm_path'], 
            config['data']['map_yaml_path']
        )
        print(f"Map loaded: {map_info.width}x{map_info.height} cells @ {map_info.resolution:.3f} m/cell")
    except FileNotFoundError as e:
        print(f"Error loading map: {e}")
        print("Please ensure 'map_pgm_path' and 'map_yaml_path' in the global CONFIG dictionary are correct.")
        return

    # --- 2. Pre-compute Likelihood Field ---
    print("Pre-computing likelihood field (this may take a moment)...")
    start_time = time.time()
    likelihood_field = compute_likelihood_field(
        map_info, 
        config['localization']['likelihood_sigma'],
        config['localization']['likelihood_max_dist']
    )
    print(f"Likelihood field computed in {time.time() - start_time:.2f}s")
    
    # --- 3. Initialize Belief ---
    print("Initializing belief grid...")
    # P(x_0) = Uniform distribution
    belief_grid = np.ones((map_info.height, map_info.width))
    # Remove belief from occupied cells
    belief_grid[map_info.occupancy_grid > 0.5] = 0.0
    belief_grid = belief_grid / np.sum(belief_grid)
    
    # --- 4. Load Sensor Data ---
    print("Loading sensor data...")
    # We use the 'load_sensor_data' function
    # It will now get the path from the global CONFIG dict
    sensor_log = load_sensor_data(config)
    if not sensor_log:
        print("Failed to load sensor data. Exiting.")
        return
    print(f"Loaded {len(sensor_log)} data points.")

    # --- 5. Run Localization Loop ---
    last_gt_pose = None
    
    for i, sensor_data in enumerate(sensor_log):
        print(f"\n--- Processing Timestamp {sensor_data['timestamp']} (Step {i+1}/{len(sensor_log)}) ---")
        start_step_time = time.time()
        
        current_gt_pose = sensor_data['pose']
        gt_x_m, gt_y_m, gt_theta_rad = current_gt_pose
        gt_grid_x, gt_grid_y = world_to_grid(gt_x_m, gt_y_m, map_info)

        # --- Prediction Step (Motion Model) ---
        if last_gt_pose:
            dx_m = current_gt_pose[0] - last_gt_pose[0]
            dy_m = current_gt_pose[1] - last_gt_pose[1]
            motion = (dx_m, dy_m)
            
            print(f"  Applying motion: dx={dx_m:.2f}m, dy={dy_m:.2f}m")
            belief_grid = prediction_step(
                belief_grid, 
                motion, 
                map_info, 
                config['localization']['motion_diffusion_factor']
            )
        else:
            print("  Skipping prediction step (first frame).")

        # --- Correction Step (Sensor Model) ---
        belief_grid = correction_step(
            belief_grid, 
            sensor_data, 
            map_info, 
            likelihood_field, 
            config
        )

        # --- Find Best Estimate ---
        est_grid_y, est_grid_x = np.unravel_index(
            np.argmax(belief_grid), 
            belief_grid.shape
        )
        est_x_m, est_y_m = grid_to_world(est_grid_x, est_grid_y, map_info)
        max_prob = np.max(belief_grid)
        
        prob_at_gt = 0.0
        if 0 <= gt_grid_x < map_info.width and 0 <= gt_grid_y < map_info.height:
             prob_at_gt = belief_grid[gt_grid_y, gt_grid_x]
        else:
            print("  Warning: Ground truth is outside map bounds.")

        # --- 6. Print and Compare ---
        print("\n  --- Results ---")
        print(f"  Step Time: {time.time() - start_step_time:.2f}s")
        print(f"  Ground Truth (World): ({gt_x_m:.2f}m, {gt_y_m:.2f}m)")
        print(f"  Ground Truth (Grid):  ({gt_grid_x}, {gt_grid_y})")
        print(f"  Estimated Pos (World): ({est_x_m:.2f}m, {est_y_m:.2f}m)")
        print(f"  Estimated Pos (Grid):  ({est_grid_x}, {est_grid_y})")
        print(f"  Position Error: {math.dist((gt_x_m, gt_y_m), (est_x_m, est_y_m)):.3f} m")
        print(f"  Highest Belief: {max_prob:.4e}")
        print(f"  Belief at GT:   {prob_at_gt:.4e}")

        # Update last pose for next iteration
        last_gt_pose = current_gt_pose
    
    print("\n--- Localization Complete ---")

if __name__ == "__main__":
    main()

